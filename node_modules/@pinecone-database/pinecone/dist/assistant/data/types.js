"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.FinishReasonEnum = exports.ChatModelEnum = void 0;
/**
 * An enum constant representing the models that can be used for chatting with an assistant. The default is 'gpt-4o'.
 *
 * This enum is provided for convenience but is not enforced. You can pass any string value
 * as the model parameter. New models may be added by without requiring an SDK update.
 * @see [Choose a model](https://docs.pinecone.io/guides/assistant/chat-with-assistant#choose-a-model)
 */
exports.ChatModelEnum = {
    Gpt4o: 'gpt-4o',
    Gpt41: 'gpt-4.1',
    O4Mini: 'o4-mini',
    ClaudeSonnet45: 'claude-sonnet-4-5',
    Gemini25Pro: 'gemini-2.5-pro',
};
/**
 * Indicates why the chat response generation stopped. This signals the end of the response.
 *
 * - `stop`: The model finished generating the response.
 *
 * - `length`: Generation was cut off because the maximum number of tokens allowed was reached.
 *
 * - `content_filter`: Generation stopped because content was blocked by content filtering rules
 *   (for example, content that contains hate speech or violent material).
 *
 * - `tool_calls`: Generation stopped because a tool call was triggered.
 *
 * - `function_call`: Generation stopped because a function call was triggered.
 *
 * This enum is provided for convenience but is not enforced.
 */
exports.FinishReasonEnum = {
    Stop: 'stop',
    Length: 'length',
    ContentFilter: 'content_filter',
    ToolCalls: 'tool_calls',
    FunctionCall: 'function_call',
};
//# sourceMappingURL=types.js.map